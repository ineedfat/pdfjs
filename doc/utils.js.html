<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: utils.js</title>
    
    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">
    
    <h1 class="page-title">Source: utils.js</h1>
    
    


    
    <section>
        <article>
            <pre class="prettyprint source"><code>ï»¿// this will run on &lt;=IE9, possibly some niche browsers
// new webkit-based, FireFox, IE10 already have native version of this.
if (typeof btoa === 'undefined') {
    window.btoa = function (data) {
        // DO NOT ADD UTF8 ENCODING CODE HERE!!!!

        // UTF8 encoding encodes bytes over char code 128
        // and, essentially, turns an 8-bit binary streams
        // (that base64 can deal with) into 7-bit binary streams. 
        // (by default server does not know that and does not recode the data back to 8bit)
        // You destroy your data.

        // binary streams like jpeg image data etc, while stored in JavaScript strings,
        // (which are 16bit arrays) are in 8bit format already.
        // You do NOT need to char-encode that before base64 encoding.

        // if you, by act of fate
        // have string which has individual characters with code
        // above 255 (pure unicode chars), encode that BEFORE you base64 here.
        // you can use absolutely any approch there, as long as in the end,
        // base64 gets an 8bit (char codes 0 - 255) stream.
        // when you get it on the server after un-base64, you must 
        // UNencode it too, to get back to 16, 32bit or whatever original bin stream.

        // Note, Yes, JavaScript strings are, in most cases UCS-2 - 
        // 16-bit character arrays. This does not mean, however,
        // that you always have to UTF8 it before base64.
        // it means that if you have actual characters anywhere in
        // that string that have char code above 255, you need to
        // recode *entire* string from 16-bit (or 32bit) to 8-bit array.
        // You can do binary split to UTF16 (BE or LE)
        // you can do utf8, you can split the thing by hand and prepend BOM to it,
        // but whatever you do, make sure you mirror the opposite on
        // the server. If server does not expect to post-process un-base64
        // 8-bit binary stream, think very very hard about messing around with encoding.

        // so, long story short:
        // DO NOT ADD UTF8 ENCODING CODE HERE!!!!

        /* @preserve
        ====================================================================
        base64 encoder
        MIT, GPL
    
        version: 1109.2015
        discuss at: http://phpjs.org/functions/base64_encode
        +   original by: Tyler Akins (http://rumkin.com)
        +   improved by: Bayron Guevara
        +   improved by: Thunder.m
        +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
        +   bugfixed by: Pellentesque Malesuada
        +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
        +   improved by: Rafal Kukawski (http://kukawski.pl)
        +   			 Daniel Dotsenko, Willow Systems Corp, willow-systems.com
        ====================================================================
        */

        var b64 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=", b64a = b64.split(''), o1, o2, o3, h1, h2, h3, h4, bits, i = 0,
            ac = 0,
            enc = "",
            tmp_arr = [];

        do { // pack three octets into four hexets
            o1 = data.charCodeAt(i++);
            o2 = data.charCodeAt(i++);
            o3 = data.charCodeAt(i++);

            bits = o1 &lt;&lt; 16 | o2 &lt;&lt; 8 | o3;

            h1 = bits >> 18 & 0x3f;
            h2 = bits >> 12 & 0x3f;
            h3 = bits >> 6 & 0x3f;
            h4 = bits & 0x3f;

            // use hexets to index into b64, and append result to encoded string
            tmp_arr[ac++] = b64a[h1] + b64a[h2] + b64a[h3] + b64a[h4];
        } while (i &lt; data.length);

        enc = tmp_arr.join('');
        var r = data.length % 3;
        return (r ? enc.slice(0, r - 3) : enc) + '==='.slice(r || 3);

        // end of base64 encoder MIT, GPL
    };
}

if (typeof atob === 'undefined') {
    window.atob = function (data) {
        // http://kevin.vanzonneveld.net
        // +   original by: Tyler Akins (http://rumkin.com)
        // +   improved by: Thunder.m
        // +      input by: Aman Gupta
        // +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
        // +   bugfixed by: Onno Marsman
        // +   bugfixed by: Pellentesque Malesuada
        // +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
        // +      input by: Brett Zamir (http://brett-zamir.me)
        // +   bugfixed by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
        // *     example 1: base64_decode('S2V2aW4gdmFuIFpvbm5ldmVsZA==');
        // *     returns 1: 'Kevin van Zonneveld'
        // mozilla has this native
        // - but breaks in 2.0.0.12!
        //if (typeof this.window['atob'] == 'function') {
        //    return atob(data);
        //}
        var b64 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";
        var o1, o2, o3, h1, h2, h3, h4, bits, i = 0,
            ac = 0,
            dec = "",
            tmp_arr = [];

        if (!data) {
            return data;
        }

        data += '';

        do { // unpack four hexets into three octets using index points in b64
            h1 = b64.indexOf(data.charAt(i++));
            h2 = b64.indexOf(data.charAt(i++));
            h3 = b64.indexOf(data.charAt(i++));
            h4 = b64.indexOf(data.charAt(i++));

            bits = h1 &lt;&lt; 18 | h2 &lt;&lt; 12 | h3 &lt;&lt; 6 | h4;

            o1 = bits >> 16 & 0xff;
            o2 = bits >> 8 & 0xff;
            o3 = bits & 0xff;

            if (h3 == 64) {
                tmp_arr[ac++] = String.fromCharCode(o1);
            } else if (h4 == 64) {
                tmp_arr[ac++] = String.fromCharCode(o1, o2);
            } else {
                tmp_arr[ac++] = String.fromCharCode(o1, o2, o3);
            }
        } while (i &lt; data.length);

        dec = tmp_arr.join('');

        return dec;
    };
}
var to8bitStream = function (text, flags) {
    /* PDF 1.3 spec:
    "For text strings encoded in Unicode, the first two bytes must be 254 followed by
    255, representing the Unicode byte order marker, U+FEFF. (This sequence conflicts
    with the PDFDocEncoding character sequence thorn ydieresis, which is unlikely
    to be a meaningful beginning of a word or phrase.) The remainder of the
    string consists of Unicode character codes, according to the UTF-16 encoding
    specified in the Unicode standard, version 2.0. Commonly used Unicode values
    are represented as 2 bytes per character, with the high-order byte appearing first
    in the string."

    In other words, if there are chars in a string with char code above 255, we
    recode the string to UCS2 BE - string doubles in length and BOM is prepended.

    HOWEVER!
    Actual *content* (body) text (as opposed to strings used in document properties etc)
    does NOT expect BOM. There, it is treated as a literal GID (Glyph ID)

    Because of Adobe's focus on "you subset your fonts!" you are not supposed to have
    a font that maps directly Unicode (UCS2 / UTF16BE) code to font GID, but you could
    fudge it with "Identity-H" encoding and custom CIDtoGID map that mimics Unicode
    code page. There, however, all characters in the stream are treated as GIDs,
    including BOM, which is the reason we need to skip BOM in content text (i.e. that
    that is tied to a font).

    To signal this "special" PDFEscape / to8bitStream handling mode,
    API.text() function sets (unless you overwrite it with manual values
    given to API.text(.., flags) )
        flags.autoencode = true
        flags.noBOM = true

    */

    /*
    `flags` properties relied upon:
    .sourceEncoding = string with encoding label. 
        "Unicode" by default. = encoding of the incoming text.
        pass some non-existing encoding name 
        (ex: 'Do not touch my strings! I know what I am doing.')
        to make encoding code skip the encoding step.
    .outputEncoding = Either valid PDF encoding name 
        (must be supported by jsPDF font metrics, otherwise no encoding)
        or a JS object, where key = sourceCharCode, value = outputCharCode
        missing keys will be treated as: sourceCharCode === outputCharCode
    .noBOM
        See comment higher above for explanation for why this is important
    .autoencode
        See comment higher above for explanation for why this is important
    */

    var i, l, undef;

    if (flags === undef) {
        flags = {};
    }

    var sourceEncoding = flags.sourceEncoding ? sourceEncoding : 'Unicode', encodingBlock, outputEncoding = flags.outputEncoding, newtext, isUnicode, ch, bch;
    // This 'encoding' section relies on font metrics format 
    // attached to font objects by, among others, 
    // "Willow Systems' standard_font_metrics plugin"
    // see jspdf.plugin.standard_font_metrics.js for format
    // of the font.metadata.encoding Object.
    // It should be something like
    //   .encoding = {'codePages':['WinANSI....'], 'WinANSI...':{code:code, ...}}
    //   .widths = {0:width, code:width, ..., 'fof':divisor}
    //   .kerning = {code:{previous_char_code:shift, ..., 'fof':-divisor},...}
    if ((flags.autoencode || outputEncoding) &&
        fonts[activeFontKey].metadata &&
        fonts[activeFontKey].metadata[sourceEncoding] &&
        fonts[activeFontKey].metadata[sourceEncoding].encoding) {
        encodingBlock = fonts[activeFontKey].metadata[sourceEncoding].encoding;

        // each font has default encoding. Some have it clearly defined.
        if (!outputEncoding && fonts[activeFontKey].encoding) {
            outputEncoding = fonts[activeFontKey].encoding;
        }

        // Hmmm, the above did not work? Let's try again, in different place.
        if (!outputEncoding && encodingBlock.codePages) {
            outputEncoding = encodingBlock.codePages[0]; // let's say, first one is the default
        }

        if (typeof outputEncoding === 'string') {
            outputEncoding = encodingBlock[outputEncoding];
        }
        // we want output encoding to be a JS Object, where
        // key = sourceEncoding's character code and 
        // value = outputEncoding's character code.
        if (outputEncoding) {
            isUnicode = false;
            newtext = [];
            for (i = 0, l = text.length; i &lt; l; i++) {
                ch = outputEncoding[text.charCodeAt(i)];
                if (ch) {
                    newtext.push(
                        String.fromCharCode(ch)
                    )
                } else {
                    newtext.push(
                        text[i]
                    );
                }

                // since we are looping over chars anyway, might as well
                // check for residual unicodeness
                if (newtext[i].charCodeAt(0) >> 8 /* more than 255 */) {
                    isUnicode = true;
                }
            }
            text = newtext.join('');
        }
    }

    i = text.length;
    // isUnicode may be set to false above. Hence the triple-equal to undefined
    while (isUnicode === undef && i !== 0) {
        if (text.charCodeAt(i - 1) >> 8 /* more than 255 */) {
            isUnicode = true;
        }
        i--;
    }
    if (!isUnicode) {
        return text;
    } else {
        newtext = flags.noBOM ? [] : [254, 255];
        for (i = 0, l = text.length; i &lt; l; i++) {
            ch = text.charCodeAt(i);
            bch = ch >> 8 // divide by 256
            if (bch >> 8 /* something left after dividing by 256 second time */) {
                throw new Error("Character at position " + i.toString(10) + " of string '" + text + "' exceeds 16bits. Cannot be encoded into UCS-2 BE");
            }
            newtext.push(bch);
            newtext.push(ch - (bch &lt;&lt; 8));
        }
        return String.fromCharCode.apply(undef, newtext);
    }
};
var pdfEscape = function (text, flags) {
    // doing to8bitStream does NOT make this PDF display unicode text. For that
    // we also need to reference a unicode font and embed it - royal pain in the rear.

    // There is still a benefit to to8bitStream - PDF simply cannot handle 16bit chars,
    // which JavaScript Strings are happy to provide. So, while we still cannot display
    // 2-byte characters property, at least CONDITIONALLY converting (entire string containing) 
    // 16bit chars to (USC-2-BE) 2-bytes per char + BOM streams we ensure that entire PDF
    // is still parseable.
    // This will allow immediate support for unicode in document properties strings.
    return to8bitStream(text, flags).replace(/\\/g, '\\\\').replace(/\(/g, '\\(').replace(/\)/g, '\\)');
};

var checkValidRect = function (rect) {
    if (!rect || typeof rect !== 'object' || rect.length !== 4) {
        console.warn('Invalid Rect');
        return false;
    }
    for (var i = 0; i &lt; 4; i++) {
        if (typeof rect[i] !== 'number') {
            console.warn('Invalid Rect');
            return false;
        }
    }
    return true;
};
var f = function (number) {
    return number.toFixed(2);
}
// simplified (speedier) replacement for sprintf's %.3f conversion  
var f3 = function (number) {
    return number.toFixed(3);
};
// simplified (speedier) replacement for sprintf's %02d
var padd2 = function (number) {
    var n = (number).toFixed(0);
    if (number &lt; 10) return '0' + n;
    else return n;
};
// simplified (speedier) replacement for sprintf's %02d
padd10 = function (number) {
    var n = (number).toFixed(0);
    if (n.length &lt; 10) return new Array(11 - n.length).join('0') + n;
    else return n;
};
// simplified (speedier) replacement for sprintf's %.2f conversion
/**
@namespace
*@memberof pdfJS.
*/
var utils = {
    /**
    *@readonly
    *@enum {array of int}
    */
    paperFormat: {
        'a3': [841.89, 1190.55],
        'a4': [595.28, 841.89],
        'a5': [420.94, 595.28],
        'letter': [612, 792],
        'legal': [612, 1008]
    }
};</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Index</a></h2><h3>Classes</h3><ul><li><a href="pdfJS.doc.html">doc</a></li><li><a href="pdfJS.font.html">font</a></li><li><a href="pdfJS.obj.html">obj</a></li><li><a href="pdfJS.pageNode.html">pageNode</a></li><li><a href="pdfJS.pageTreeNode.html">pageTreeNode</a></li><li><a href="pdfJS.stream.html">stream</a></li></ul><h3>Namespaces</h3><ul><li><a href="pdfJS.html">pdfJS</a></li><li><a href="pdfJS.utils.html">utils</a></li></ul>
</nav>

<br clear="both">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.2.0-dev</a> on Sun Feb 17 2013 19:10:02 GMT-0800 (PST)
</footer>

<script> prettyPrint(); </script>
</body>
</html>
